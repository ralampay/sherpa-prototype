{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook attempts speaker diarization.\n",
        "\n",
        "I would have liked to have used [`speechbox`](https://github.com/huggingface/speechbox), but I run into some dependency conflicts involving `torch` and `pyannote.audio`."
      ],
      "metadata": {
        "id": "VIOEHE143zRN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set-up"
      ],
      "metadata": {
        "id": "dMKG4t-i4P1R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hrvBbz1wGni"
      },
      "outputs": [],
      "source": [
        "!pip install -qq https://github.com/pyannote/pyannote-audio/archive/refs/heads/develop.zip\n",
        "!pip install huggingface_hub openai-whisper"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# only if you're accessing this notebook in the cloud\n",
        "\n",
        "# !git clone https://github.com/ralampay/sherpa-prototype.git\n",
        "# %cd sherpa-prototype/notebooks"
      ],
      "metadata": {
        "id": "iq-v_yLyz4mK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "3GbCxPCuxCYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUDIO_FILENAME = 'audio/1.mp3' #@param{'type': 'string'}"
      ],
      "metadata": {
        "id": "DUwaLnisLKTZ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p diarization_outputs"
      ],
      "metadata": {
        "id": "Y2c9LWHm4XPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transcribe"
      ],
      "metadata": {
        "id": "UbBYjg684e2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import json\n",
        "\n",
        "recognizer = whisper.load_model(\"medium\")\n",
        "speech = recognizer.transcribe(AUDIO_FILENAME)\n",
        "\n",
        "with open('diarization_outputs/1.json', 'w') as f:\n",
        "  json.dump(speech, f)"
      ],
      "metadata": {
        "id": "TFrl2yIVM6JZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Diarize"
      ],
      "metadata": {
        "id": "9ncWs4Bl4SuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyannote.audio import Pipeline\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "diarizer = Pipeline.from_pretrained(\"pyannote/speaker-diarization\").to(device)"
      ],
      "metadata": {
        "id": "dLu0rBY4wND6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diarization = diarizer(AUDIO_FILENAME)\n",
        "with open(\"diarization_outputs/1.rttm\", \"w\") as rttm:\n",
        "  diarization.write_rttm(rttm)"
      ],
      "metadata": {
        "id": "yzE-rr8KyA8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combine diarization with transcript"
      ],
      "metadata": {
        "id": "qHUq_LF04ru7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyannote.database.util import load_rttm\n",
        "import json\n",
        "\n",
        "diarization = load_rttm('diarization_outputs/1.rttm')['1']\n",
        "\n",
        "with open('diarization_outputs/1.json', 'r') as f:\n",
        "  speech = json.load(f)"
      ],
      "metadata": {
        "id": "8mLiat1XeoZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view transcript\n",
        "\n",
        "for speech_segment in speech['segments']:\n",
        "  print(f\"start={speech_segment['start']:.1f}s stop={speech_segment['end']:.1f}s {speech_segment['text']}\")"
      ],
      "metadata": {
        "id": "dYpyTU07NJgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view diarization\n",
        "\n",
        "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
        "  print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")\n",
        "\n",
        "diarization"
      ],
      "metadata": {
        "id": "BW1ubIe7LcFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# aggregate consecutive speaker segments with the same speaker id\n",
        "# code from https://github.com/huggingface/speechbox/blob/main/src/speechbox/diarize.py\n",
        "\n",
        "old_speaker_segments = list(diarization.itertracks(yield_label=True))\n",
        "speaker_segments = [{'start': old_speaker_segments[0][0].start, 'end': old_speaker_segments[0][0].end, 'speaker': old_speaker_segments[0][-1]}]\n",
        "for turn, _, speaker in old_speaker_segments[1:]:\n",
        "  if speaker == speaker_segments[-1]['speaker']:\n",
        "    speaker_segments[-1]['end'] = turn.end\n",
        "  else:\n",
        "    speaker_segments.append({'start': turn.start, 'end': turn.end, 'speaker': speaker})"
      ],
      "metadata": {
        "id": "8Ln5ITLQhmLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create diarized transcript\n",
        "# code from https://github.com/huggingface/speechbox/blob/main/src/speechbox/diarize.py\n",
        "\n",
        "import numpy as np\n",
        "asr_end_times = np.array([seg['end'] for seg in speech['segments']])\n",
        "asr_end_times\n",
        "\n",
        "diarized_transcript = []\n",
        "speech_segments = speech['segments']\n",
        "for speaker_seg in speaker_segments:\n",
        "  stop_idx = np.argmin(np.abs(asr_end_times - speaker_seg['end']))\n",
        "  diarized_transcript.append({'start': speaker_seg['start'], 'end': asr_end_times[stop_idx], 'speaker': speaker_seg['speaker'], 'text': ' '.join([speech_seg['text'] for speech_seg in speech_segments[:stop_idx+1]])})\n",
        "  speech_segments = speech_segments[stop_idx+1:]\n",
        "  asr_end_times = asr_end_times[stop_idx+1:]"
      ],
      "metadata": {
        "id": "rtsRhBS9hzGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view diarized transcript\n",
        "\n",
        "for seg in diarized_transcript:\n",
        "  print(f'{seg[\"speaker\"].replace(\"_\", \" \")}: {seg[\"text\"]}')"
      ],
      "metadata": {
        "id": "fswwEeFsH7s4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}